is.matrix(o)
p <- as.data.frame(matrix(c(1:20), nrow = 4))
p
is.data.frame(p)
rm(list = ls())
n1 <- 15
n1
typeof(n1)
c1 <- "PK"
c1
typeof(c1)
l1 <- TRUE
l1
typeof(l1)
l2 <- F
l2
typeof(l2)
v1 <- c(1, 2, 3, 4, 5)
v1
is.vector(v1)
v2 <- c("a", "n", "d", "y")
v2
is.vector(v2)
v3 <- c(TRUE, FALSE, FALSE, TRUE, TRUE)
v3
is.vector(v3)
is.vector(n1)
m1 <- matrix(c(T, F,F,T,T,F), nrow = 3, byrow = T)
m1
a1 <- array(c(1:24), c(4,3,2))
a1
vNum <- c(1, 2, 3)
vChar <- c("a", "b", "c")
vBool <- c(T, F, T)
df1 <- cbind(vNum, vChar, vBool)
df1
df2 <- as.data.frame(cbind(vNum, vChar, vBool))
df2
MN <- c("Kato", "NKato", "Rochester", "St. Paul")
MD <- c("OC", "Delawar", "Salisbury", "West OC")
IL <- c("California", "SoCal", "NoCal", "Chicago")
US <- cbind(MN, MD, IL)
US
USA <- as.data.frame(cbind(MN, MD, IL))
USA
list1 <- list(MN,MD,IL)
list1
list2 <- list(MN, MD, list1)
list2
m <- c(1, "2", T)
m
typeof(m)
n <- as.integer("2","4","6")
n
typeof(n)
o <- matrix(c(1:15), nrow = 3)
o
is.matrix(o)
p <- as.data.frame(matrix(c(1:20), nrow = 4))
p
is.data.frame(p)
rm(list = ls())
n1 <- 15
n1
typeof(n1)
c1 <- "PK"
c1
typeof(c1)
l1 <- TRUE
l1
typeof(l1)
l2 <- F
l2
typeof(l2)
v1 <- c(1, 2, 3, 4, 5)
v1
is.vector(v1)
v2 <- c("a", "n", "d", "y")
v2
is.vector(v2)
v3 <- c(TRUE, FALSE, FALSE, TRUE, TRUE)
v3
is.vector(v3)
is.vector(n1)
m1 <- matrix(c(T, F,F,T,T,F), nrow = 3, byrow = T)
m1
a1 <- array(c(1:24), c(4,3,2))
a1
vNum <- c(1, 2, 3)
vChar <- c("a", "b", "c")
vBool <- c(T, F, T)
df1 <- cbind(vNum, vChar, vBool)
df1
df2 <- as.data.frame(cbind(vNum, vChar, vBool))
df2
MN <- c("Kato", "NKato", "Rochester", "St. Paul")
MD <- c("OC", "Delawar", "Salisbury", "West OC")
IL <- c("California", "SoCal", "NoCal", "Chicago")
US <- cbind(MN, MD, IL)
US
USA <- as.data.frame(cbind(MN, MD, IL))
USA
list1 <- list(MN,MD,IL)
list1
list2 <- list(MN, MD, list1)
list2
m <- c(1, "2", T)
m
typeof(m)
n <- as.integer("2","4","6")
n
typeof(n)
o <- matrix(c(1:15), nrow = 3)
o
is.matrix(o)
p <- as.data.frame(matrix(c(1:20), nrow = 4))
p
is.data.frame(p)
rm(list = ls())
if(!require("pacman")) install.packages("pacman")
if(!require("pacman")) install.packages("pacman")
install.packages("tidyverse")
#titanic
?Titanic
Titanic
?iris
iris
rm(list = ls())
pacman::p_load(pacman, party, rio, tidyverse)
(df <- read_csv("F:\Users\mjpk2\OneDrive\Desktop\Documents\Fall 2019\Data Science 2019\Learning R\Ex_Files_Learning_R\Exercise Files\data\StateData.xlsx"))
(df <- read_csv("Fall 2019\Data Science 2019\Learning R\Ex_Files_Learning_R\Exercise Files\data\StateData.xlsx"))
(df <- read_csv("data\StateData.xlsx"))
diamonds%>%
select(price, color)%>%
boxplot()
pacman::p_load(pacman, tidyverse)
?diamonds
diamonds
diamonds%>%
select(price, color)%>%
boxplot()
diamonds%>%
select(color, price)%>%
boxplot()
diamonds%>%
select(color, price)%>%
plot()
diamonds%>%
select(color, price)%>%
boxplot(price ~ color,
data = .,
col = "blue")
rm(list = ls())
pacman::p_load(pacman, tidyverse)
install.packages("twitteR")
install.packages("RCurl")
install.packages("tm")
install.packages("wordcloud")
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
bd_tweets = searchTwitter("Coronavirus", n=500, lang="en")
bd_text = sapply(bd_tweets, function(x) x$getText())
bd_corpus = Corpus(VectorSource(bd_text))
inspect(bd_corpus[1])
# Clean the corpus by removing punctuation, numbers, and white spaces
bd_clean  <- tm_map(bd_corpus, removePunctuation)
bd_clean  <- tm_map(bd_clean, removeNumbers)
bd_clean  <- tm_map(bd_clean, stripWhitespace)
wordcloud(bd_clean)
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5))
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5), color = rainbow(50))
wordcloud(bd_clean, random.order = F, max.words = 300, scale = c(3, 0.5), color = rainbow(50))
#Instructions and code for creating world clouds in R using Twitter data
#Watch the video for deatils
# Install and load the following packages
install.packages("twitteR")
install.packages("RCurl")
install.packages("tm")
install.packages("wordcloud")
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
# Create a developer account at apps.twitter.com to create an app and to get the following keys
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
# Get the tweets from Twitter
bd_tweets = searchTwitter("china", n=500, lang="en")
install.packages("twitteR")
install.packages("twitteR")
install.packages("twitteR")
install.packages("twitteR")
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
# Create a developer account at apps.twitter.com to create an app and to get the following keys
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
# Get the tweets from Twitter
bd_tweets = searchTwitter("china", n=500, lang="en")
bd_text = sapply(bd_tweets, function(x) x$getText())
# Create a corpus
bd_corpus = Corpus(VectorSource(bd_text))
# Inspect the corpus
inspect(bd_corpus[1])
# Clean the corpus by removing punctuation, numbers, and white spaces
bd_clean  <- tm_map(bd_corpus, removePunctuation)
bd_clean  <- tm_map(bd_clean, removeNumbers)
bd_clean  <- tm_map(bd_clean, stripWhitespace)
# Create Word Cloud from clean data
wordcloud(bd_clean)
# Modify your Word Cloud
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5))
wordcloud(bd_clean, random.order = F, max.words = 300, scale = c(3, 0.5), color = rainbow(50))
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5), color = rainbow(50))
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
# Create a developer account at apps.twitter.com to create an app and to get the following keys
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
# Get the tweets from Twitter
bd_tweets = searchTwitter("nepal", n=500, lang="en")
bd_text = sapply(bd_tweets, function(x) x$getText())
# Create a corpus
bd_corpus = Corpus(VectorSource(bd_text))
# Inspect the corpus
inspect(bd_corpus[1])
# Clean the corpus by removing punctuation, numbers, and white spaces
bd_clean  <- tm_map(bd_corpus, removePunctuation)
bd_clean  <- tm_map(bd_clean, removeNumbers)
bd_clean  <- tm_map(bd_clean, stripWhitespace)
# Create Word Cloud from clean data
wordcloud(bd_clean)
# Modify your Word Cloud
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5))
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5), color = rainbow(50))
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
# Create a developer account at apps.twitter.com to create an app and to get the following keys
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
# Get the tweets from Twitter
bd_tweets = searchTwitter("mankato", n=500, lang="en", geocode='39.0458,76.6413, 100mi')
bd_text = sapply(bd_tweets, function(x) x$getText())
# Create a corpus
bd_corpus = Corpus(VectorSource(bd_text))
# Inspect the corpus
inspect(bd_corpus[1])
# Clean the corpus by removing punctuation, numbers, and white spaces
bd_clean  <- tm_map(bd_corpus, removePunctuation)
bd_clean  <- tm_map(bd_clean, removeNumbers)
bd_clean  <- tm_map(bd_clean, stripWhitespace)
# Create Word Cloud from clean data
wordcloud(bd_clean)
# Modify your Word Cloud
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5))
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5), color = rainbow(50))
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
bd_tweets = searchTwitter("mankato", n=500, lang="en", geocode='39.0458,76.6413, 100mi')
bd_text = sapply(bd_tweets, function(x) x$getText())
bd_tweets = searchTwitter("mankato", n=500, lang="en", geocode='39.0458,76.6413, 80mi')
bd_text = sapply(bd_tweets, function(x) x$getText())
bd_corpus = Corpus(VectorSource(bd_text))
# Inspect the corpus
inspect(bd_corpus[1])
# Clean the corpus by removing punctuation, numbers, and white spaces
bd_clean  <- tm_map(bd_corpus, removePunctuation)
bd_clean  <- tm_map(bd_clean, removeNumbers)
bd_clean  <- tm_map(bd_clean, stripWhitespace)
# Create Word Cloud from clean data
wordcloud(bd_clean)
# Modify your Word Cloud
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5))
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5), color = rainbow(50))
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
# Create a developer account at apps.twitter.com to create an app and to get the following keys
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
# Get the tweets from Twitter
bd_tweets = searchTwitter("mankato", n=500, lang="en")
bd_text = sapply(bd_tweets, function(x) x$getText())
# Create a corpus
bd_corpus = Corpus(VectorSource(bd_text))
# Inspect the corpus
inspect(bd_corpus[1])
# Clean the corpus by removing punctuation, numbers, and white spaces
bd_clean  <- tm_map(bd_corpus, removePunctuation)
bd_clean  <- tm_map(bd_clean, removeNumbers)
bd_clean  <- tm_map(bd_clean, stripWhitespace)
# Create Word Cloud from clean data
wordcloud(bd_clean)
# Modify your Word Cloud
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5))
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5), color = rainbow(50))
bd_tweets = searchTwitter("mankato", n=500, lang="en", geocode='76.6413,39.0458, 80mi')
bd_tweets = searchTwitter("mankato", n=500, lang="en", geocode='39.0458,76.6413, 80mi')
bd_tweets = searchTwitter("mankato", n=500, lang="en", geocode='39.0458,76.6413, 800mi')
bd_tweets = searchTwitter("mankato", n=500, lang="en", geocode='38.336502,-75.084908, 800mi')
bd_tweets = searchTwitter("mankato", n=500, lang="en", geocode='38.336502,-75.084908, 80mi')
bd_tweets = searchTwitter("love", n=500, lang="en", geocode='38.336502,-75.084908, 80mi')
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
# Create a developer account at apps.twitter.com to create an app and to get the following keys
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
# Get the tweets from Twitter
bd_tweets = searchTwitter("love", n=500, lang="en", geocode='38.336502,-75.084908, 80mi')
bd_text = sapply(bd_tweets, function(x) x$getText())
bd_tweets = searchTwitter("love", n=500, lang="en", geocode='40.6892,74.0445, 80mi')
bd_tweets = searchTwitter("love", n=500, lang="en", geocode='44.986656,-93.258133, 80mi')
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
# Create a developer account at apps.twitter.com to create an app and to get the following keys
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
bd_tweets = searchTwitter("love", n=500, lang="en", geocode='44.986656,-93.258133, 80mi')
bd_tweets = searchTwitter("rbukralia", n=500, lang="en", geocode='44.986656,-93.258133, 80mi')
bd_tweets = searchTwitter("rbukralia", n=500, lang="en")
bd_tweets = searchTwitter("america", n=500, lang="en", geocode='44.986656,-93.258133, 80mi')
bd_tweets = searchTwitter("america", n=500, lang="en")
View(bd_tweets)
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
# Create a developer account at apps.twitter.com to create an app and to get the following keys
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
# Get the tweets from Twitter
bd_tweets = searchTwitter("america", n=500, lang="en")
bd_text = sapply(bd_tweets, function(x) x$getText())
# Create a corpus
bd_corpus = Corpus(VectorSource(bd_text))
# Inspect the corpus
inspect(bd_corpus[1])
# Clean the corpus by removing punctuation, numbers, and white spaces
bd_clean  <- tm_map(bd_corpus, removePunctuation)
bd_clean  <- tm_map(bd_clean, removeNumbers)
bd_clean  <- tm_map(bd_clean, stripWhitespace)
# Create Word Cloud from clean data
wordcloud(bd_clean)
# Modify your Word Cloud
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5))
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5), color = rainbow(50))
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
# Create a developer account at apps.twitter.com to create an app and to get the following keys
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
# Get the tweets from Twitter
bd_tweets = searchTwitter("Arthur Gunn", n=500, lang="en")
bd_text = sapply(bd_tweets, function(x) x$getText())
# Create a corpus
bd_corpus = Corpus(VectorSource(bd_text))
inspect(bd_corpus[1])
# Clean the corpus by removing punctuation, numbers, and white spaces
bd_clean  <- tm_map(bd_corpus, removePunctuation)
bd_clean  <- tm_map(bd_clean, removeNumbers)
bd_clean  <- tm_map(bd_clean, stripWhitespace)
# Create Word Cloud from clean data
wordcloud(bd_clean)
# Modify your Word Cloud
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5))
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5), color = rainbow(50))
library(ggplot2)
data(diamonds)
ggplot(diamonds, aes(x = carat)) +
geom_histogram(bins = 25, color = 'black', fill = 'skyblue') +
labs(x = 'Diamond Caret', y = 'Count', title = 'Histogram of Diamonds Caret')
# + geom_vline(aes(xintercept = mean(diamonds$carat, na.rm = TRUE), color = 'mean'), show.legend = TRUE, size = 1.5)
ggplot(diamonds, aes(x = carat, y = price, color = price)) +
geom_point()
# Boxplot (diamonds carat) with ggplot2
ggplot(diamonds, aes(x = cut, y = carat, fill = cut)) +
geom_boxplot(outlier.color = "black", outlier.shape = 16)
ggplot(diamonds, aes(x = cut, y = carat, fill = cut)) +
geom_boxplot(outlier.color = "black", outlier.shape = 16, notch = FALSE)
# Boxplot (diamonds carat) with ggplot2
ggplot(diamonds, aes(x = cut, y = carat, fill = cut)) +
geom_boxplot(outlier.color = "black", outlier.shape = 16, notch = TRUE)
# Boxplot (diamonds carat) with ggplot2
ggplot(diamonds, aes(x = cut, y = carat, fill = cut)) +
geom_boxplot(outlier.color = "black", outlier.shape = 16)
ggplot(diamonds, aes(x = cut, y = carat, fill = cut)) +
geom_violin(trim = FALSE) +
geom_boxplot(width=0.1, fill = "white")
summary(diamonds)
head(diamonds)
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
# Create a developer account at apps.twitter.com to create an app and to get the following keys
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
# Get the tweets from Twitter
bd_tweets = searchTwitter("Minnesota", n=1000, lang="en")
bd_text = sapply(bd_tweets, function(x) x$getText())
# Create a corpus
bd_corpus = Corpus(VectorSource(bd_text))
# Inspect the corpus
inspect(bd_corpus[1])
# Clean the corpus by removing punctuation, numbers, and white spaces
bd_clean  <- tm_map(bd_corpus, removePunctuation)
bd_clean  <- tm_map(bd_clean, removeNumbers)
bd_clean  <- tm_map(bd_clean, stripWhitespace)
# Create Word Cloud from clean data
wordcloud(bd_clean)
# Modify your Word Cloud
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5))
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5), color = rainbow(50))
require(twitteR)
require(RCurl)
require(tm)
require(wordcloud)
consumer_key  <- 'S54EZ2hKvQfgY3CvKPGN7zpH1'
consumer_secret  <- 'PeiwP9dW3WhEF8XKsJQrjoSvhEM6dF5xIhs5Fl4aZKHnVwkrIl'
access_token  <- '1042980095437099013-6bTXz0hMglRbUsbRF7YCYsYWbjVabO'
access_secret  <- 'jIKGwLIj5fjHy0DM9vlkCeQSwDcvCfNHrz4gHiXUYCZE1'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
bd_tweets = searchTwitter("Minnesota", n=1000, lang="en")
bd_text = sapply(bd_tweets, function(x) x$getText())
bd_corpus = Corpus(VectorSource(bd_text))
inspect(bd_corpus[1])
bd_clean  <- tm_map(bd_corpus, removePunctuation)
bd_clean  <- tm_map(bd_clean, removeNumbers)
bd_clean  <- tm_map(bd_clean, stripWhitespace)
wordcloud(bd_clean)
wordcloud(bd_clean, random.order = F, max.words = 50, scale = c(3, 0.5))
wordcloud(bd_clean, random.order = F, max.words = 25, scale = c(3, 0.5), color = rainbow(25))
View(bd_tweets)
View(bd_tweets)
View(bd_clean)
View(bd_clean)
setwd("F:/Users/mjpk2/OneDrive/Desktop/Documents/Spring 2020/Machine Learning (ML)/Association Rule Learning/Apriori/Apriori")
# Support = item sold per day*days of week / Total transaction in a week = 3*7/7500
rules <- apriori(dataset, parameter = list(support = 0.003, confidence = 0.4))
dataset <- read.csv('Market_Basket_Optimisation.csv', header = FALSE)
# Data Preprocessing
# Transfer Dataset into Sparse Martix
#install.packages('arules')
library(arules)
dataset <- read.transactions('Market_Basket_Optimisation.csv', sep = ',', rm.duplicates = TRUE) #Removing Duplicates
summary(dataset)
itemFrequencyPlot(dataset, topN = 100)
rules <- apriori(dataset, parameter = list(support = 0.003, confidence = 0.4))
inspect(sort(rules, by = 'lift')[1:10])
setwd("F:/Users/mjpk2/OneDrive/Desktop/Documents/Spring 2020/Machine Learning (ML)/Association Rule Learning/Eclat/Eclat")
library(arules)
dataset = read.transactions('Market_Basket_Optimisation.csv', sep = ',', rm.duplicates = TRUE)
summary(dataset)
rules = eclat(data = dataset, parameter = list(support = 0.004, minlen = 2))
inspect(sort(rules, by = 'support')[1:10])
